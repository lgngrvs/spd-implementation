{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "374687f7-c6bd-462e-92cb-95a74322304b",
   "metadata": {},
   "source": [
    "# Stochastic Parameter Decomposition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b4be581-416b-4231-b780-c5cabb7142f6",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42f5b19f-26f8-4a66-85ca-5f81c949767d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import all the torch stuff, as well as the ViT stuff and such\n",
    "# import plotly.express as px\n",
    "# import torch\n",
    "# from jaxtyping import Int, Float\n",
    "# from typing import List, Optional, Tuple\n",
    "# from tqdm import tqdm\n",
    "# from transformer_lens.hook_points import HookPoint\n",
    "# from transformer_lens import utils, HookedTransformer, HookedTransformerConfig, FactoredMatrix, ActivationCache\n",
    "# import circuitsvis as cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c791fb62-d6be-4926-b345-c518a5239fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import Tensor\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import einops\n",
    "import typing\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbd14d16-8e3e-4efe-9d5f-7f29610d6b83",
   "metadata": {},
   "source": [
    "## Toy Model MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "48df6266-0231-4c6d-a813-19f4bf12553b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a SPDHookedTransformer Class\n",
    "# that extends the hookedTransformer\n",
    "# which inherits all the previous class stuff\n",
    "# but also contains the SPD training algo?\n",
    "\n",
    "# how is everything actually structured? \n",
    "\"\"\"\n",
    "Maybe I should start with implementing it on a simple MLP setup. \n",
    "\n",
    "Orig network:\n",
    "- 1 layer MLP 5-2-5 (defined as usual with torch.Sequential presumably)\n",
    "\n",
    "SPD network:\n",
    "let's give it 10 subcomponents per layer\n",
    "then it's just like 10 matmuls? \n",
    "maybe i should define it like ant did in the toy models of superposition paper\n",
    "stick them all into a trenchcoat\n",
    "this might be easier once I have defined the toy modle\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "50be6f25-5489-4445-82c0-914779cc7a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"num_layers\": 1,\n",
    "    \"pre_embed_size\": 100,\n",
    "    \"in_size\": 1000,\n",
    "    \"hidden_size\": 50,\n",
    "    \"subcomponents_per_layer\": 10, \n",
    "    \"beta_1\": 1, \n",
    "    \"beta_2\": 1, \n",
    "    \"beta_3\": 1, \n",
    "    \"causal_imp_min\": 1, \n",
    "    \"num_mask_samples\": 20,\n",
    "    \"importance_mlp_size\": 10,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "5a426a65-b7dc-4e68-9e35-da69dbdf7743",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ToyResidMLP(nn.Module):\n",
    "    def __init__(self, config, device=\"mps\"):\n",
    "        super().__init__()\n",
    "        # Initialize Weights for the\n",
    "        self.num_layers, self.pre_embed_size, self.in_size, self.hidden_size = config[\"num_layers\"], config[\"pre_embed_size\"], config[\"in_size\"], config[\"hidden_size\"]\n",
    "        self.device = device\n",
    "        self.W_embed = nn.Parameter(torch.empty((self.pre_embed_size, self.in_size)))\n",
    "        self.W_unembed = nn.Parameter(torch.empty((self.in_size, self.pre_embed_size)))\n",
    "        self.W_in = nn.ParameterList([torch.empty((self.in_size, self.hidden_size), device=device) for i in range(self.num_layers)])\n",
    "        self.W_out = nn.ParameterList([torch.empty((self.hidden_size, self.in_size), device=device) for i in range(self.num_layers)])\n",
    "        self.b = nn.ParameterList([torch.zeros((self.hidden_size,), device=device) for i in range(self.num_layers)])\n",
    "\n",
    "        for param in [self.W_embed, self.W_unembed] + list(self.W_in) + list(self.W_out): \n",
    "            nn.init.xavier_normal_(param)\n",
    "        \n",
    "    def forward(self, x): \n",
    "        \n",
    "        assert x.shape[1] == self.pre_embed_size, f\"Input shape {x.shape[0]} does not match model's accepted size {self.pre_embed_size}\"\n",
    "        # embed \n",
    "        x_resid = torch.einsum(\"np,pi->ni\", x.clone(), self.W_embed)\n",
    "        N, D = x_resid.shape\n",
    "\n",
    "        \n",
    "        for l in range(self.num_layers):\n",
    "            hidden = F.relu(torch.einsum(\"nd,dh -> nh\", x_resid, self.W_in[l]) + self.b[l])\n",
    "            layer_out = torch.einsum(\"nh,hd -> nd\", hidden, self.W_out[l])\n",
    "            x_resid = x_resid + layer_out\n",
    "        # am I supposed to have a embed and out?\n",
    "        x_out = torch.einsum(\"ni,ip->np\", x_resid, self.W_unembed) \n",
    "        return x_out\n",
    "\n",
    "\n",
    "# Generated by LLM bc I am lazy and this is not important to me learning stuff atm\n",
    "class SparseAutoencoderDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Dataset for learning to reconstruct sparse inputs.\n",
    "    Each item is (input, target) where target is the input itself (or ReLU of input).\n",
    "    \"\"\"\n",
    "    def __init__(self, in_dim=100, n_samples=10000, sparsity=0.9, device=\"mps\"):\n",
    "        super().__init__()\n",
    "        self.in_dim = in_dim\n",
    "        self.n_samples = n_samples\n",
    "        self.device = device\n",
    "\n",
    "        # Pre-generate all samples\n",
    "        self.inputs = []\n",
    "        self.targets = []\n",
    "        \n",
    "        for _ in range(n_samples):\n",
    "            # Sparse input: each entry is -1, 0, or 1, with sparsity\n",
    "            x = np.random.choice([0, -1, 1], size=(in_dim,), p=[1-sparsity, sparsity/2, sparsity/2])\n",
    "            x = torch.tensor(x, dtype=torch.float32, device=device)\n",
    "            target = F.relu(x)\n",
    "            \n",
    "            self.inputs.append(x)\n",
    "            self.targets.append(target)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.n_samples\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.inputs[idx], self.targets[idx]\n",
    "\n",
    "def train_toy_resid_mlp(\n",
    "    model,\n",
    "    dataloader,\n",
    "    lr=1e-3,\n",
    "    num_epochs=10,\n",
    "    device=\"mps\",\n",
    "    print_every=1\n",
    "):\n",
    "    model.train()\n",
    "    model.to(device)\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=lr)\n",
    "    loss_fn = nn.MSELoss()\n",
    "    for epoch in range(num_epochs):\n",
    "        total_loss = 0.0\n",
    "        for x, y in tqdm(dataloader, desc=f\"Epoch {epoch+1}/{num_epochs}\"):\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            y_pred = model(x)\n",
    "            loss = loss_fn(y_pred, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item() * x.size(0)\n",
    "        avg_loss = total_loss / len(dataloader.dataset)\n",
    "        if (epoch+1) % print_every == 0:\n",
    "            print(f\"Epoch {epoch+1}: avg MSE loss = {avg_loss:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "d67d9bbc-74ee-4eca-8a38-90c245095172",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/20: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████| 79/79 [00:00<00:00, 101.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: avg MSE loss = 365801.498374\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/20: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████| 79/79 [00:00<00:00, 100.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: avg MSE loss = 348.291439\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/20: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████| 79/79 [00:00<00:00, 102.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: avg MSE loss = 42.082283\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/20: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████| 79/79 [00:00<00:00, 106.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: avg MSE loss = 21.854127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/20: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████| 79/79 [00:00<00:00, 104.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: avg MSE loss = 13.048978\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/20: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████| 79/79 [00:00<00:00, 106.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: avg MSE loss = 8.327664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/20: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████| 79/79 [00:00<00:00, 106.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: avg MSE loss = 5.563310\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/20: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████| 79/79 [00:00<00:00, 104.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: avg MSE loss = 3.846435\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/20: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████| 79/79 [00:00<00:00, 103.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: avg MSE loss = 2.737103\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/20: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████| 79/79 [00:00<00:00, 102.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: avg MSE loss = 1.999273\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/20: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████| 79/79 [00:00<00:00, 93.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11: avg MSE loss = 1.495929\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/20: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████| 79/79 [00:00<00:00, 106.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12: avg MSE loss = 1.147356\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/20: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████| 79/79 [00:00<00:00, 100.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13: avg MSE loss = 0.903899\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/20: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████| 79/79 [00:00<00:00, 106.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14: avg MSE loss = 0.731857\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/20: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████| 79/79 [00:00<00:00, 103.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15: avg MSE loss = 0.610296\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/20: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████| 79/79 [00:00<00:00, 103.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16: avg MSE loss = 0.524525\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/20: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████| 79/79 [00:00<00:00, 104.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17: avg MSE loss = 0.464593\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/20: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████| 79/79 [00:00<00:00, 106.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18: avg MSE loss = 0.423585\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/20: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████| 79/79 [00:00<00:00, 100.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19: avg MSE loss = 0.396789\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/20: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████| 79/79 [00:00<00:00, 105.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20: avg MSE loss = 0.380262\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "## LLM-Generated Usage Example\n",
    "\n",
    "torch.autograd.set_detect_anomaly(True)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Config\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    # Dataset and DataLoader\n",
    "    # Dataset and DataLoader\n",
    "    dataset = SparseAutoencoderDataset(\n",
    "        in_dim=100,\n",
    "        n_samples=10000,\n",
    "        sparsity=0.9,\n",
    "        device=device,\n",
    "    )\n",
    "    dataloader = DataLoader(dataset, batch_size=128, shuffle=True)\n",
    "    # Model\n",
    "    model = ToyResidMLP(config, device=device)\n",
    "    # Train\n",
    "    train_toy_resid_mlp(model, dataloader, lr=8e-2, num_epochs=20, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "838c72b4-6661-4d00-b27d-cee3f7ac01ac",
   "metadata": {},
   "source": [
    "## SPD Model and Train Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b9bda061-7487-44ce-9201-dc1f6a34b302",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0000, 0.0000, 0.0000, 0.3000, 0.7000, 1.0000, 1.0000])\n"
     ]
    }
   ],
   "source": [
    "# generated by LLM\n",
    "\n",
    "class HardSigmoid(nn.Module):\n",
    "    \"\"\"\n",
    "    Implements the hard sigmoid activation function as described in the paper:\n",
    "        σ_H(x) = 0 if x <= 0\n",
    "               = x if 0 < x < 1\n",
    "               = 1 if x >= 1\n",
    "    This is equivalent to: torch.clamp(x, min=0.0, max=1.0)\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Clamp values between 0 and 1\n",
    "        return torch.clamp(x, min=0.0, max=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50310679-3db3-4b7d-8a8b-24c32dc176e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SPDModelMLP(nn.Module): \n",
    "    # fix the betas stuff below that's basically a type hint\n",
    "    def __init__(self, target_model, config, device=\"mps\"): \n",
    "        self.device = device\n",
    "        self.target_model = target_model\n",
    "        self.num_layers, self.pre_embed_size, self.in_size, self.hidden_size, self.imp_hidden_size = config[\"num_layers\"], config[\"pre_embed_size\"], config[\"in_size\"], config[\"hidden_size\"], config[\"importance_mlp_size\"]\n",
    "        assert self.device == target_model.device, \"Models not on same device\"\n",
    "        self.C = config[\"subcomponents_per_layer\"]\n",
    "        self.hypers = dict(list(config.items())[4:]) # sets the \"hypers\" to contain all the hyperparameters for the model\n",
    "        \n",
    "        # Subcomponent vectors, each of shape C by in_size; to be used\n",
    "        # with outer product to create our low-rank subcomponent matrices\n",
    "        self.V_embed = nn.Parameter(torch.empty((self.C, self.pre_embed_size,), device=device))\n",
    "        self.U_embed = nn.Parameter(torch.empty((self.C, self.in_size,), device=device))\n",
    "        self.V_unembed = nn.Parameter(torch.empty((self.C, self.in_size,), device=device))\n",
    "        self.U_unembed = nn.Parameter(torch.empty((self.C, self.pre_embed_size,), device=device))\n",
    "\n",
    "        self.V_in = nn.ParameterList([torch.empty((self.C, self.in_size,), device=device) for i in range(num_layers)])\n",
    "        self.U_in = nn.ParameterList([torch.empty((self.C, self.hidden_size,), device=device) for i in range(num_layers)]) \n",
    "        self.V_out = nn.ParameterList([torch.empty((self.C, self.hidden_size,), device=device) for i in range(num_layers)])\n",
    "        self.U_out = nn.ParameterList([torch.empty((self.C, self.in_size,), device=device) for i in range(num_layers)])\n",
    "        \n",
    "        \n",
    "        # idk what you do with the biases lol\n",
    "        self.b = nn.ParameterList([torch.zeros((self.hidden_size,), device=device) for i in range(num_layers)])\n",
    "        \n",
    "        # this is so horrible I'm sorry\n",
    "        # gate_in_in is the gate_in weights for the in subcomponent of each layer\n",
    "        # gate_in_out is gate_in weights for the out component\n",
    "        # they each get an extra one on the end which is for the embed matrix\n",
    "        self.imp_W_gate_in_in = nn.ParameterList([torch.empty(C, 1, self.imp_hidden_size) for i in range(num_layers)+1])\n",
    "        self.imp_W_gate_out_in = nn.ParameterList([torch.empty(C, self.imp_hidden_size, 1) for i in range(num_layers)+1]) \n",
    "        self.imp_b_in_in = nn.ParameterList([torch.empty(C, self.imp_hidden_size) for i in range(num_layers)+1])\n",
    "        self.imp_b_out_in = nn.ParameterList([torch.empty(C, 1) for i in range(num_layers)+1])\n",
    "        \n",
    "        self.imp_W_gate_in_out = nn.ParameterList([torch.empty(C, 1, self.imp_hidden_size) for i in range(num_layers)+1])\n",
    "        self.imp_W_gate_out_out = nn.ParameterList([torch.empty(C, self.imp_hidden_size, 1) for i in range(num_layers)+1]) \n",
    "        self.imp_b_in_out = nn.ParameterList([torch.empty(C, self.imp_hidden_size) for i in range(num_layers)+1])\n",
    "        self.imp_b_out_out = nn.ParameterList([torch.empty(C, 1) for i in range(num_layers)+1])\n",
    "        \n",
    "        # self.pred_weights = torch.empty((num_layers, self.C), device=device)\n",
    "\n",
    "        for param in self.V_in + self.U_in + self.V_out + self.U_out + self.b: \n",
    "            # using xavier anyway -- note that the variance etc is\n",
    "            # changed because we take the outer product in the \n",
    "            # forward pass\n",
    "            nn.init.xavier_normal_(param)\n",
    "\n",
    "        \n",
    "    def forward(self, x, return_activs_and_weights=False, masks=None): # Regular run. Unclear whether I should have masking when I do a regular forward pass.\n",
    "        v_activations = []\n",
    "        weight_matrices = []\n",
    "        x_in = x.clone()\n",
    "        layerwise_resids = []\n",
    "\n",
    "        if masks is not None: \n",
    "            \n",
    "            v_activ_embed = torch.einsum(\"np,cp->nc\", x_in, self.V_embed) * masks[-1][\"embed\"] # TODO: ADD MASKS FOR EMBED\n",
    "            x_embedded = torch.einsum(\"nc,ci->nh\", v_activ_embed, self.U_embed)\n",
    "            x_resid = x_embedded.clone()\n",
    "                        \n",
    "            for l in range(self.num_layers):\n",
    "                # may have dimension issues in these einsums :(\n",
    "                ### Run the forward pass just for this layer\n",
    "                v_activ_layer_in = torch.einsum(\"ni,ci->nc\", x_resid, self.V_in[l]) * masks[l][\"in\"]\n",
    "                layer_hidden = torch.einsum(\"nc,ch->nh\", v_activ_layer_in, self.U_in[l])\n",
    "                v_activ_layer_out = torch.einsum(\"nh,ch->nc\", layer_in, self.V_out[l]) * masks[l][\"out\"]\n",
    "                layer_out = torch.einsum(\"nc,ci->ni\", v_activ_layer_in, self.U_out[l])\n",
    "                x_resid = x_resid + layer_out\n",
    "\n",
    "                # Run the layerwise forward pass for the whole model, with masking only this layer\n",
    "                x_resid_layerwise = x_embedded.clone() # pre-embedded\n",
    "                for l_2 in self.num_layers: # oh god this is so awful. literally sobbing rn. i can't believe I'm writing it like this\n",
    "                    if l_2 == l: \n",
    "                        v_activ_layer_in_l = torch.einsum(\"ni,ci->nc\", x_resid_layerwise, self.V_in[l]) * masks[l][\"in\"]\n",
    "                        layer_hidden_l = torch.einsum(\"nc,ch->nh\", v_activ_layer_in_l, self.U_in[l])\n",
    "                        v_activ_layer_l = torch.einsum(\"nh,ch->nc\", layer_in_l, self.V_out[l]) * masks[l][\"out\"]\n",
    "                        layer_out_l = torch.einsum(\"nc,ci->ni\", v_activ_layer_in_l, self.U_out[l])\n",
    "                    else: # THE SAME EXACT THING EXCEPT WITHOUT THE MASKS >_< \n",
    "                        v_activ_layer_in_l = torch.einsum(\"ni,ci->nc\", x_resid_layerwise, self.V_in[l])\n",
    "                        layer_hidden_l = torch.einsum(\"nc,ch->nh\", v_activ_layer_in_l, self.U_in[l])\n",
    "                        v_activ_layer_l = torch.einsum(\"nh,ch->nc\", layer_in_l, self.V_out[l])\n",
    "                        layer_out_l = torch.einsum(\"nc,ci->ni\", v_activ_layer_in_l, self.U_out[l])\n",
    "                    x_resid_layerwise = x_resid_layerwise + layer_out_l\n",
    "                v_activ_unembed_layerwise = torch.einsum(\"nc,cp->np\", torch.einsum(\"ni,ci->nc\", x_resid, self.V_unembed) * masks[-1][\"unembed\"], self.U_unembed)\n",
    "                layerwise_resids.append(x_resid_layerwise)\n",
    "            \n",
    "            v_activ_unembed = torch.einsum(\"ni,ci->nc\", x_resid, self.V_unembed) * masks[-1][\"unembed\"]\n",
    "            x_out = torch.einsum(\"nc,cp->np\", v_activ_unembed, self.U_unembed)\n",
    "\n",
    "                                \n",
    "        else: \n",
    "            W_embed = torch.einsum(\"cp, ci -> cpi\", self.V_embed, self.U_embed).sum(dim=0)\n",
    "            x_resid = torch.einsum(\"np, pi -> ni\", x_in, self.W_embed)\n",
    "            \n",
    "            for l in range(self.num_layers):\n",
    "                # Use outer product to create weights for the layer, then sum all the subcomponents\n",
    "                W_in = torch.einsum(\"ci,ch-> cih\", self.V_in[l], self.U_in[l]).sum(dim=0) # shape i h\n",
    "                W_out = torch.einsum(\"ch,ci-> chi\", self.V_out[l], self.U_out[l]).sum(dim=0) # shape h i\n",
    "                if return_activs_and_weights == True:\n",
    "                    weight_matrices.append({\"in\": W_in, \"out\", W_out})\n",
    "                # COMPUTE \n",
    "                layer_in = torch.einsum(\"ni,ih -> nh\", x_resid, W_in) + self.b[l]\n",
    "                layer_out = torch.einsum(\"nh,hi->ni\", F.relu(layer_in), W_out)\n",
    "            \n",
    "            if return_activs_and_weights == True: \n",
    "                # calculate activations\n",
    "                v_activ_layer_in = torch.einsum(\"ni,ci->nc\", x_resid, self.V_in[l]).unsqueeze(-1)\n",
    "                v_activ_layer_out = torch.einsum(\"nh,ch->nc\", layer_in, self.V_out[l]).unsqueeze(-1)\n",
    "                # both are now shape n,c,1\n",
    "                v_activations.append({\"in\": v_activ_layer_in, \"out\": v_activ_layer_out})\n",
    "                \n",
    "                # code to make sure I'm not doing some goofy shit with the activations at the beginning\n",
    "                check_layer_in_uv = torch.einsum(\"nc,ch->nh\", v_activ_layer_in, self.U_in[l])\n",
    "                assert layer_in == check_layer_in_uv, \"Subcomponent activations not calculated correctly\"\n",
    "                # would in theory have one for the second too but I'm being lazy\n",
    "            \n",
    "            x_resid = x_resid + layer_out\n",
    "            W_unembed = torch.einsum(\"ci, cp-> cip\", self.V_unembed, self.U_unembed)\n",
    "            x_out = torch.einsum(\"ni, ip -> np\", x_resid, self.W_embed)\n",
    "            weight_matrices.append({\"embed\": W_embed, \"unembed\": W_unembed})\n",
    "            # putting the embed matrices at the end of the masks. since we iterate through l in range(num_layers) this will not get added! :D\n",
    "\n",
    "        if return_activs_and_weights:\n",
    "            return x_resid, v_activations, weight_matrices \n",
    "        else if masks is not None: \n",
    "            return x_resid, layerwise_resids\n",
    "        else: \n",
    "            return x_resid\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6731eff5-4248-4332-85c5-ca3afc41f411",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_batch(config): \n",
    "    # return shape N, config.in_size \n",
    "    pass\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "one last thing to do to make the model work\n",
    "\n",
    "parameters:\n",
    "    model,\n",
    "    dataloader,\n",
    "    lr=1e-3,\n",
    "    num_epochs=10,\n",
    "    device=\"mps\",\n",
    "    print_every=1\n",
    "    \n",
    "--- \n",
    "\n",
    "    model.train()\n",
    "    model.to(device)\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=lr)\n",
    "    loss_fn = nn.MSELoss()\n",
    "    for epoch in range(num_epochs):\n",
    "        total_loss = 0.0\n",
    "        for x, y in tqdm(dataloader, desc=f\"Epoch {epoch+1}/{num_epochs}\"):\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            y_pred = model(x)\n",
    "            loss = loss_fn(y_pred, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item() * x.size(0)\n",
    "        avg_loss = total_loss / len(dataloader.dataset)\n",
    "        if (epoch+1) % print_every == 0:\n",
    "            print(f\"Epoch {epoch+1}: avg MSE loss = {avg_loss:.6f}\")\n",
    "\"\"\"\n",
    "\n",
    "def train_SPD(spd_model, dataloader, \"more stuff goes here\"): # could also implement this by passing in the original model?\n",
    "    \n",
    "    for t in train_steps:\n",
    "        x = generate_batch() # TODO. possibly put in the model? idk if needed.\n",
    "        N = x.shape[0]     # x is shape N by in_size\n",
    "        C = model.C\n",
    "        target_model = spd_model.target_model\n",
    "        hard_sigmoid = HardSigmoid()\n",
    "        \n",
    "        # COMPUTE TARGET OUTPUT\n",
    "        with torch.no_grad(): \n",
    "            target_out = spd_model.target_model(x)\n",
    "    \n",
    "        # FAITHFULNESS LOSS\n",
    "        \n",
    "        spd_output, spd_activations spd_weights = model(x, return_activations = True, return_weight_matrices = True)\n",
    "        squared_error = 0\n",
    "        for l in range(num_layers):\n",
    "            in_diff = target_model.W_in[l] - spd_weights[l][\"in\"]\n",
    "            out_diff = target_model.W_out[l] - spd_weights[l][\"out\"]\n",
    "            \n",
    "            # torch.linalg.matrix_norm defaults to the frobenius norm\n",
    "            # this takes the frobenius norm of the diff and then squares it\n",
    "            squared_error_layer = torch.linalg.matrix_norm(in_diff) ** 2 + torch.linalg.matrix_norm(out_diff) ** 2 \n",
    "            squared_error = squared_error + squared_error_layer\n",
    "            \n",
    "        mean_squared_error = squared_error/num_layers\n",
    "        l_faithfulness = mean_squared_error\n",
    "        \n",
    "    \n",
    "        ## IMPORTANCE-MINIMALITY LOSS\n",
    "        \n",
    "        pred_importances = []\n",
    "        l_importance_minimality = 0\n",
    "    \n",
    "        components_imp_pred_embed_hidden = F.gelu(torch.einsum(\"nco,cos->ncs\", spd_activations[-1][\"embed\"], spd_model.imp_W_gate_in_in[-1]) + spd_model.imp_b_in[-1])\n",
    "        components_imp_pred_embed = hard_sigmoid(torch.einsum(\"ncs,cso->nco\", components_imp_pred_hidden, spd_model.imp_W_gate_out_in[-1]) + spd_model.imp_b_out_in[-1])\n",
    "        \n",
    "        components_imp_pred_unembed_hidden = F.gelu(torch.einsum(\"nco,cos->ncs\", spd_activations[-1][\"unembed\"], spd_model.imp_W_gate_in_in[-1]) + spd_model.imp_b_in[-1])\n",
    "        components_imp_pred_unembed = hard_sigmoid(torch.einsum(\"ncs,cso->nco\", components_imp_pred_unembed_hidden, spd_model.imp_W_gate_out_in[-1]) + spd_model.imp_b_out_in[-1])\n",
    "        l_importance_minimality = l_importance_minimality + (components_imp_pred_embed ** spd_model.hypers[\"importance_mlp_size\"]) + (components_imp_pred_unembed ** spd_model.hypers[\"importance_mlp_size\"])\n",
    "    \n",
    "        for l in range(num_layers):\n",
    "            # both activations are n by c containing dot product so we already have hard_sigmoid\n",
    "            # spd_activations[l][inout] is shape n,c,1 (nco)\n",
    "            # imp_W_in is c by 1 by imp_size (cos)\n",
    "            # want to map to ncs then back to nco\n",
    "            # imp_b_in is shape (C, s) so should broadcast to ncs nicely\n",
    "            \n",
    "            # TODO: DEFINE hard_sigmoid AS A TORCH MODULE SO IT CAN CALCULATE THE DERIVATIVE \n",
    "            # in theory should write this as a bunch of models stored in the main model, but that's not how i did it and i've already \n",
    "            # written this, shrug\n",
    "            # oh my god this is so bad \n",
    "            # imp_W_gate_in_in is the gate in for the W_in, etc\n",
    "            components_imp_pred_hidden_in = F.gelu(torch.einsum(\"nco,cos->ncs\", spd_activations[l][\"in\"], spd_model.imp_W_gate_in_in[l]) + spd_model.imp_b_in_in[l])\n",
    "            components_pred_layer_in = hard_sigmoid(torch.einsum(\"ncs,cso->nco\", components_imp_pred_hidden, spd_model.imp_W_gate_out_in[l]) + spd_model.imp_b_out_in[l])\n",
    "    \n",
    "            #same thing for the out matrix in layer l\n",
    "            components_imp_pred_hidden_out = F.gelu(torch.einsum(\"nco,cos->ncs\", spd_activations[l][\"out\"], spd_model.imp_W_gate_in_out[l]) + spd_model.imp_b_in_out[l])\n",
    "            components_pred_layer_out = hard_sigmoid(torch.einsum(\"ncs,cso->nco\", components_imp_pred_hidden, spd_model.imp_W_gate_out_out[l]) + spd_model.imp_b_out_out[l])\n",
    "            \n",
    "            pred_importances.append({\"in\": components_pred_layer_in, \"out\": components_pred_layer_out)\n",
    "            l_importance_minimality = l_importance_minimality + (components_pred_layer_in ** spd_model.hypers[\"importance_mlp_size\"]) + (components_pred_layer_out ** spd_model.hypers[\"importance_mlp_size\"])\n",
    "        \n",
    "        l_importance_minimality /= N # divide by N, the batch size, to avg across the batch (notated as B in the paper)\n",
    "    \n",
    "    \n",
    "        ## STOCHASTIC RECONSTRUCTION LOSS \n",
    "    \n",
    "        l_stochastic_recon = 0\n",
    "        l_stochastic_recon_layerwise = 0\n",
    "        R = torch.rand(model.hypers[\"num_mask_samples\"], N, model.num_layers+1, 2, C)\n",
    "        layer_masks = []\n",
    "    \n",
    "        for s in range(model.hypers[\"num_mask_samples\"]):\n",
    "            # Running this with a for loop. This is slow; I'd ideally just run \n",
    "            # something like M = G[None, :, :] + (1 - G[None, :, :]) * R\n",
    "            # But I think there's a clarity tradeoff here so I'm just going to do this for now\n",
    "            layer_mask_embed = pred_importances[-1][\"embed\"].squeeze() + (torch.ones_like(pred_importances[-1][\"embed\"]) - pred_importances[l][\"embed\"])*R[s,:,l,0,:]\n",
    "            layer_mask_unembed = pred_importances[-1][\"unembed\"].squeeze() + (torch.ones_like(pred_importances[l][\"unembed\"]) - pred_importances[l][\"unembed\"]) * R[s,:,l,1,:]\n",
    "            \n",
    "            for l in range(num_layers):\n",
    "                # ugh, this is pretty bad. Ideally I'd go back and refactor so that I don't \n",
    "                # have separate in and out weights, but this is what I have. going to keep it\n",
    "                # like this for now, but will refactor once I have something that works.\n",
    "                # components pred in is shape N, C, 1, squeeze to N, C. there are L of them\n",
    "                # R is N, L, C, sample just l to get N, C\n",
    "                # I want masks for each component on each layer on each datapoint, so\n",
    "                # masks should be one C vector for each layer, per-datapoint. so NLC\n",
    "                layer_mask_in = pred_importances[l][\"in\"].squeeze() + (torch.ones_like(pred_importances[l][\"in\"]) - pred_importances[l][\"in\"]) * R[s,:,l,0,:]\n",
    "                layer_mask_out = pred_importances[l][\"out\"].squeeze() + (torch.ones_like(pred_importances[l][\"out\"]) - pred_importances[l][\"out\"]) * R[s,:,l,1,:]\n",
    "                # these are both shape N, C \n",
    "                layer_masks.append({\"in\": layer_mask_in, \"out\": layer_mask_out})\n",
    "                \n",
    "            masked_out, layerwise_masked_outs = model(x, masks=layer_masks)\n",
    "            l_stochastic_recon = l_stochastic_recon + torch.linalg.matrix_norm(target_out - masked_out) # uses matrix norm of difference\n",
    "            for i in range(len(layerwise_masked_outs)-1):\n",
    "                l_stochastic_recon_layerwise = l_stochastic_recon_layerwise + torch.linalg.matrix_norm(target_out - layerwise_masked_outs[i])\n",
    "    \n",
    "        l_stochastic_recon /= model.hypers[\"num_mask_samples\"]\n",
    "        l_stochastic_recon_layerwise /= (model.hypers[\"num_mask_samples\"] * model.num_layers)\n",
    "    \n",
    "        loss = l_faithfulness + model.hypers[\"beta1\"] * l_stochastic_recon + model.hypers[\"beta2\"] * l_stochastic_recon_layerwise + model.hypers[\"beta3\"] * l_importance_minimality\n",
    "\n",
    "    \"\"\"\n",
    "    TODO: \n",
    "    - generate batches\n",
    "        - i want a dataloader object that i can iterate through\n",
    "        - my first test will be the 1-layer 50-hidden 100-in dim\n",
    "    - start testing\n",
    "    - wrap functions with tqdm\n",
    "    \"\"\"\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "interp-replication",
   "language": "python",
   "name": "interp-replication"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
